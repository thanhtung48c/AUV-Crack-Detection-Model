{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5a83842",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) d:\\bld\\libopencv_1641992799878\\work\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0x58acfac3::Set<1,-1,-1>,struct cv::impl::A0x58acfac3::Set<0,2,5>,2>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28084/3550955745.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[0mbi_blur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbilateralFilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Bi'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbi_blur\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m     \u001b[0mcrack_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbi_blur\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m     \u001b[1;31m#ShiTomasi Feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[0mshi\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mshi_tomasi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28084/3550955745.py\u001b[0m in \u001b[0;36mPCD\u001b[1;34m(img, weak_th, strong_th)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# conversion of image to grayscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Noise reduction step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) d:\\bld\\libopencv_1641992799878\\work\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0x58acfac3::Set<1,-1,-1>,struct cv::impl::A0x58acfac3::Set<0,2,5>,2>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n"
     ]
    }
   ],
   "source": [
    "#Importing Necessary Files\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# defining the crack detector function\n",
    "   \n",
    "# here weak_th and strong_th are thresholds for\n",
    "# double thresholding step\n",
    "def PCD(img, weak_th = None, strong_th = None):\n",
    "      \n",
    "    # conversion of image to grayscale\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "       \n",
    "    # Noise reduction step\n",
    "    img = cv2.GaussianBlur(img, (5, 5), 1.6)\n",
    "       \n",
    "    # Calculating the gradients\n",
    "    gx = cv2.Sobel(np.float32(img), cv2.CV_64F, 1, 0, 3)\n",
    "    gy = cv2.Sobel(np.float32(img), cv2.CV_64F, 0, 1, 3)\n",
    "      \n",
    "    # Conversion of Cartesian coordinates to polar \n",
    "    mag, ang = cv2.cartToPolar(gx, gy, angleInDegrees = True)\n",
    "       \n",
    "    # setting the minimum and maximum thresholds \n",
    "    # for double thresholding\n",
    "    mag_max = np.max(mag)\n",
    "    if not weak_th:weak_th = mag_max * 0.1\n",
    "    if not strong_th:strong_th = mag_max * 0.5\n",
    "      \n",
    "    # getting the dimensions of the input image  \n",
    "    height, width = img.shape\n",
    "       \n",
    "    # Looping through every pixel of the grayscale \n",
    "    # image\n",
    "    for i_x in range(width):\n",
    "        for i_y in range(height):\n",
    "               \n",
    "            grad_ang = ang[i_y, i_x]\n",
    "            grad_ang = abs(grad_ang-180) if abs(grad_ang)>180 else abs(grad_ang)\n",
    "               \n",
    "            # selecting the neighbours of the target pixel\n",
    "            # according to the gradient direction\n",
    "            # In the x axis direction\n",
    "            if grad_ang<= 22.5:\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y\n",
    "              \n",
    "            # top right (diagonal-1) direction\n",
    "            elif grad_ang>22.5 and grad_ang<=(22.5 + 45):\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y-1\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y + 1\n",
    "              \n",
    "            # In y-axis direction\n",
    "            elif grad_ang>(22.5 + 45) and grad_ang<=(22.5 + 90):\n",
    "                neighb_1_x, neighb_1_y = i_x, i_y-1\n",
    "                neighb_2_x, neighb_2_y = i_x, i_y + 1\n",
    "              \n",
    "            # top left (diagonal-2) direction\n",
    "            elif grad_ang>(22.5 + 90) and grad_ang<=(22.5 + 135):\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y + 1\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y-1\n",
    "              \n",
    "            # Now it restarts the cycle\n",
    "            elif grad_ang>(22.5 + 135) and grad_ang<=(22.5 + 180):\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y\n",
    "               \n",
    "            # Non-maximum suppression step\n",
    "            if width>neighb_1_x>= 0 and height>neighb_1_y>= 0:\n",
    "                if mag[i_y, i_x]<mag[neighb_1_y, neighb_1_x]:\n",
    "                    mag[i_y, i_x]= 0\n",
    "                    continue\n",
    "   \n",
    "            if width>neighb_2_x>= 0 and height>neighb_2_y>= 0:\n",
    "                if mag[i_y, i_x]<mag[neighb_2_y, neighb_2_x]:\n",
    "                    mag[i_y, i_x]= 0\n",
    "   \n",
    "    weak_ids = np.zeros_like(img)\n",
    "    strong_ids = np.zeros_like(img)              \n",
    "    ids = np.zeros_like(img)\n",
    "       \n",
    "    # double thresholding step\n",
    "    for i_x in range(width):\n",
    "        for i_y in range(height):\n",
    "              \n",
    "            grad_mag = mag[i_y, i_x]\n",
    "              \n",
    "            if grad_mag<weak_th:\n",
    "                mag[i_y, i_x]= 0\n",
    "            elif strong_th>grad_mag>= weak_th:\n",
    "                ids[i_y, i_x]= 1\n",
    "            else:\n",
    "                ids[i_y, i_x]= 2\n",
    "       \n",
    "       \n",
    "    # finally returning the magnitude of\n",
    "    # gradients of edges\n",
    "    return mag\n",
    "\n",
    "#Shi tomasi\n",
    "\n",
    "def shi_tomasi(image):\n",
    "\n",
    "    #Converting to grayscale\n",
    "    gray_img = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #Specifying maximum number of corners as 1000\n",
    "    # 0.01 is the minimum quality level below which the corners are rejected\n",
    "    # 10 is the minimum euclidean distance between two corners\n",
    "    corners_img = cv2.goodFeaturesToTrack(gray_img,1000,0.01,10)\n",
    "    \n",
    "    corners_img = np.int0(corners_img)\n",
    "\n",
    "    for corners in corners_img:\n",
    "       \n",
    "        x,y = corners.ravel()\n",
    "        #Circling the corners in green\n",
    "        cv2.circle(image,(x,y),3,[0,255,0],-1)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Creating a VideoCapture object to read the video\n",
    "cap = cv2.VideoCapture('Sample1.mp4')\n",
    " \n",
    " \n",
    "# Loop until the end of the video\n",
    "while (cap.isOpened()):\n",
    " \n",
    "    # Capture frame-by-frame\n",
    "    #ret, frame = cap.read()\n",
    "    #frame = cv2.resize(frame, (540, 380), fx = 0, fy = 0,\n",
    "     #                    interpolation = cv2.INTER_CUBIC)\n",
    " \n",
    "    frame= cv2.imread('Test4.png')\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "    \n",
    "    \n",
    "    # conversion of BGR to grayscale is necessary to apply this operation\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    bi_blur = cv2.bilateralFilter(gray,15,80,80)\n",
    "    cv2.imshow('Bi',bi_blur)\n",
    "    crack_frame = PCD(bi_blur)\n",
    "    #ShiTomasi Feature\n",
    "    shi= shi_tomasi(frame)\n",
    "    cv2.imshow('Shi',shi)\n",
    "    \n",
    "    blur = cv2.blur(crack_frame,(3,3))\n",
    "    #img_log = np.array(blur,dtype=np.uint8)\n",
    "    \n",
    "    # Morphological Closing Operator\n",
    "    #kernel = np.ones((5,5),np.uint8)\n",
    "    #closing = cv2.morphologyEx(blur, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Create feature detecting method\n",
    "    # sift = cv2.xfeatures2d.SIFT_create()\n",
    "    # surf = cv2.xfeatures2d.SURF_create()\n",
    "    # orb = cv2.ORB_create(nfeatures=150)\n",
    "    \n",
    "    # Make featured Image\n",
    "    # keypoints, descriptors = orb.detectAndCompute(closing, None)\n",
    "    # featuredImg = cv2.drawKeypoints(closing, keypoints, None)\n",
    "    \n",
    "\n",
    "    # adaptive thresholding to use different threshold\n",
    "    # values on different regions of the frame.\n",
    "    #Thresh = cv2.adaptiveThreshold(crack_frame, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                           #cv2.THRESH_BINARY_INV, 11, 2)\n",
    " \n",
    "    cv2.imshow('C_frame', blur)\n",
    "    \n",
    "    # define q as the exit button\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "# release the video capture object\n",
    "cap.release()\n",
    "# Closes all the windows currently opened.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020e5dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Necessary Files\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# defining the crack detector function\n",
    "   \n",
    "# here weak_th and strong_th are thresholds for\n",
    "# double thresholding step\n",
    "def PCD(img, weak_th = None, strong_th = None):\n",
    "    \n",
    "    # Bilateral Filter\n",
    "    #img = cv2.bilateralFilter(img,15,80,80)\n",
    "    \n",
    "    # conversion of image to grayscale\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "       \n",
    "    # Noise reduction step\n",
    "    img = cv2.GaussianBlur(img, (5, 5), 1.6)\n",
    "       \n",
    "    # Calculating the gradients\n",
    "    gx = cv2.Sobel(np.float32(img), cv2.CV_64F, 1, 0, 3)\n",
    "    gy = cv2.Sobel(np.float32(img), cv2.CV_64F, 0, 1, 3)\n",
    "      \n",
    "    # Conversion of Cartesian coordinates to polar \n",
    "    mag, ang = cv2.cartToPolar(gx, gy, angleInDegrees = True)\n",
    "       \n",
    "    # setting the minimum and maximum thresholds \n",
    "    # for double thresholding\n",
    "    mag_max = np.max(mag)\n",
    "    if not weak_th:weak_th = mag_max * 0.1\n",
    "    if not strong_th:strong_th = mag_max * 0.5\n",
    "      \n",
    "    # getting the dimensions of the input image  \n",
    "    height, width = img.shape\n",
    "       \n",
    "    # Looping through every pixel of the grayscale \n",
    "    # image\n",
    "    for i_x in range(width):\n",
    "        for i_y in range(height):\n",
    "               \n",
    "            grad_ang = ang[i_y, i_x]\n",
    "            grad_ang = abs(grad_ang-180) if abs(grad_ang)>180 else abs(grad_ang)\n",
    "               \n",
    "            # selecting the neighbours of the target pixel\n",
    "            # according to the gradient direction\n",
    "            # In the x axis direction\n",
    "            if grad_ang<= 22.5:\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y\n",
    "              \n",
    "            # top right (diagonal-1) direction\n",
    "            elif grad_ang>22.5 and grad_ang<=(22.5 + 45):\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y-1\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y + 1\n",
    "              \n",
    "            # In y-axis direction\n",
    "            elif grad_ang>(22.5 + 45) and grad_ang<=(22.5 + 90):\n",
    "                neighb_1_x, neighb_1_y = i_x, i_y-1\n",
    "                neighb_2_x, neighb_2_y = i_x, i_y + 1\n",
    "              \n",
    "            # top left (diagonal-2) direction\n",
    "            elif grad_ang>(22.5 + 90) and grad_ang<=(22.5 + 135):\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y + 1\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y-1\n",
    "              \n",
    "            # Now it restarts the cycle\n",
    "            elif grad_ang>(22.5 + 135) and grad_ang<=(22.5 + 180):\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y\n",
    "               \n",
    "            # Non-maximum suppression step\n",
    "            if width>neighb_1_x>= 0 and height>neighb_1_y>= 0:\n",
    "                if mag[i_y, i_x]<mag[neighb_1_y, neighb_1_x]:\n",
    "                    mag[i_y, i_x]= 0\n",
    "                    continue\n",
    "   \n",
    "            if width>neighb_2_x>= 0 and height>neighb_2_y>= 0:\n",
    "                if mag[i_y, i_x]<mag[neighb_2_y, neighb_2_x]:\n",
    "                    mag[i_y, i_x]= 0\n",
    "   \n",
    "    weak_ids = np.zeros_like(img)\n",
    "    strong_ids = np.zeros_like(img)              \n",
    "    ids = np.zeros_like(img)\n",
    "       \n",
    "    # double thresholding step\n",
    "    for i_x in range(width):\n",
    "        for i_y in range(height):\n",
    "              \n",
    "            grad_mag = mag[i_y, i_x]\n",
    "              \n",
    "            if grad_mag<weak_th:\n",
    "                mag[i_y, i_x]= 0\n",
    "            elif strong_th>grad_mag>= weak_th:\n",
    "                ids[i_y, i_x]= 1\n",
    "            else:\n",
    "                ids[i_y, i_x]= 2\n",
    "       \n",
    "       \n",
    "    # finally returning the magnitude of\n",
    "    # gradients of edges\n",
    "    return mag\n",
    "\n",
    "#Shi tomasi\n",
    "\n",
    "def shi_tomasi(image):\n",
    "\n",
    "    #Converting to grayscale\n",
    "    gray_img = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #Specifying maximum number of corners as 1000\n",
    "    # 0.01 is the minimum quality level below which the corners are rejected\n",
    "    # 10 is the minimum euclidean distance between two corners\n",
    "    corners_img = cv2.goodFeaturesToTrack(gray_img,1000,0.01,10)\n",
    "    \n",
    "    corners_img = np.int0(corners_img)\n",
    "\n",
    "    for corners in corners_img:\n",
    "       \n",
    "        x,y = corners.ravel()\n",
    "        #Circling the corners in green\n",
    "        cv2.circle(image,(x,y),3,[0,255,0],-1)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "#Driver Code\n",
    "\n",
    "frame= cv2.imread('Test4.png')    \n",
    "# Display the resulting frame\n",
    "cv2.imshow('Frame', frame)\n",
    "crack_frame = PCD(frame)\n",
    "cv2.imshow('Cracked',crack_frame)    \n",
    "\n",
    "#ShiTomasi Feature\n",
    "#shi= shi_tomasi(frame)\n",
    "#cv2.imshow('Shi',shi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f782f300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
