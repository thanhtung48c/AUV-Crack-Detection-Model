{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca369b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prototype 4\n",
    "\n",
    "# importing the necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# defining the crack detector function\n",
    "   \n",
    "# here weak_th and strong_th are thresholds for\n",
    "# double thresholding step\n",
    "def PCD(img, weak_th = None, strong_th = None):\n",
    "      \n",
    "    # conversion of image to grayscale\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "       \n",
    "    # Noise reduction step\n",
    "    img = cv2.GaussianBlur(img, (5, 5), 1.6)\n",
    "       \n",
    "    # Calculating the gradients\n",
    "    gx = cv2.Sobel(np.float32(img), cv2.CV_64F, 1, 0, 3)\n",
    "    gy = cv2.Sobel(np.float32(img), cv2.CV_64F, 0, 1, 3)\n",
    "      \n",
    "    # Conversion of Cartesian coordinates to polar \n",
    "    mag, ang = cv2.cartToPolar(gx, gy, angleInDegrees = True)\n",
    "       \n",
    "    # setting the minimum and maximum thresholds \n",
    "    # for double thresholding\n",
    "    mag_max = np.max(mag)\n",
    "    if not weak_th:weak_th = mag_max * 0.1\n",
    "    if not strong_th:strong_th = mag_max * 0.5\n",
    "      \n",
    "    # getting the dimensions of the input image  \n",
    "    height, width = img.shape\n",
    "       \n",
    "    # Looping through every pixel of the grayscale \n",
    "    # image\n",
    "    for i_x in range(width):\n",
    "        for i_y in range(height):\n",
    "               \n",
    "            grad_ang = ang[i_y, i_x]\n",
    "            grad_ang = abs(grad_ang-180) if abs(grad_ang)>180 else abs(grad_ang)\n",
    "               \n",
    "            # selecting the neighbours of the target pixel\n",
    "            # according to the gradient direction\n",
    "            # In the x axis direction\n",
    "            if grad_ang<= 22.5:\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y\n",
    "              \n",
    "            # top right (diagonal-1) direction\n",
    "            elif grad_ang>22.5 and grad_ang<=(22.5 + 45):\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y-1\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y + 1\n",
    "              \n",
    "            # In y-axis direction\n",
    "            elif grad_ang>(22.5 + 45) and grad_ang<=(22.5 + 90):\n",
    "                neighb_1_x, neighb_1_y = i_x, i_y-1\n",
    "                neighb_2_x, neighb_2_y = i_x, i_y + 1\n",
    "              \n",
    "            # top left (diagonal-2) direction\n",
    "            elif grad_ang>(22.5 + 90) and grad_ang<=(22.5 + 135):\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y + 1\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y-1\n",
    "              \n",
    "            # Now it restarts the cycle\n",
    "            elif grad_ang>(22.5 + 135) and grad_ang<=(22.5 + 180):\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y\n",
    "               \n",
    "            # Non-maximum suppression step\n",
    "            if width>neighb_1_x>= 0 and height>neighb_1_y>= 0:\n",
    "                if mag[i_y, i_x]<mag[neighb_1_y, neighb_1_x]:\n",
    "                    mag[i_y, i_x]= 0\n",
    "                    continue\n",
    "   \n",
    "            if width>neighb_2_x>= 0 and height>neighb_2_y>= 0:\n",
    "                if mag[i_y, i_x]<mag[neighb_2_y, neighb_2_x]:\n",
    "                    mag[i_y, i_x]= 0\n",
    "   \n",
    "    weak_ids = np.zeros_like(img)\n",
    "    strong_ids = np.zeros_like(img)              \n",
    "    ids = np.zeros_like(img)\n",
    "       \n",
    "    # double thresholding step\n",
    "    for i_x in range(width):\n",
    "        for i_y in range(height):\n",
    "              \n",
    "            grad_mag = mag[i_y, i_x]\n",
    "              \n",
    "            if grad_mag<weak_th:\n",
    "                mag[i_y, i_x]= 0\n",
    "            elif strong_th>grad_mag>= weak_th:\n",
    "                ids[i_y, i_x]= 1\n",
    "            else:\n",
    "                ids[i_y, i_x]= 2\n",
    "       \n",
    "       \n",
    "    # finally returning the magnitude of\n",
    "    # gradients of edges\n",
    "    return mag\n",
    "\n",
    "\n",
    "\n",
    "# Creating a VideoCapture object to read the video\n",
    "cap = cv2.VideoCapture('Sample1.mp4')\n",
    " \n",
    " \n",
    "# Loop until the end of the video\n",
    "while (cap.isOpened()):\n",
    " \n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, (540, 380), fx = 0, fy = 0,\n",
    "                         interpolation = cv2.INTER_CUBIC)\n",
    " \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame', frame)\n",
    " \n",
    "    # conversion of BGR to grayscale is necessary to apply this operation\n",
    "    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    crack_frame = PCD(frame)\n",
    "    \n",
    "    blur = cv2.blur(crack_frame,(3,3))\n",
    "    #img_log = np.array(blur,dtype=np.uint8)\n",
    "    \n",
    "    # Morphological Closing Operator\n",
    "    #kernel = np.ones((5,5),np.uint8)\n",
    "    #closing = cv2.morphologyEx(blur, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Create feature detecting method\n",
    "    # sift = cv2.xfeatures2d.SIFT_create()\n",
    "    # surf = cv2.xfeatures2d.SURF_create()\n",
    "    # orb = cv2.ORB_create(nfeatures=150)\n",
    "    \n",
    "    # Make featured Image\n",
    "    # keypoints, descriptors = orb.detectAndCompute(closing, None)\n",
    "    # featuredImg = cv2.drawKeypoints(closing, keypoints, None)\n",
    "    \n",
    "\n",
    "    # adaptive thresholding to use different threshold\n",
    "    # values on different regions of the frame.\n",
    "    #Thresh = cv2.adaptiveThreshold(crack_frame, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                           #cv2.THRESH_BINARY_INV, 11, 2)\n",
    " \n",
    "    cv2.imshow('C_frame', blur)\n",
    "    \n",
    "    # define q as the exit button\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "# release the video capture object\n",
    "cap.release()\n",
    "# Closes all the windows currently opened.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0602f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "src = cv.imread(\"Test3.png\")\n",
    "cv.imshow(\"input\", src)\n",
    "\n",
    "gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n",
    "ret, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY_INV | cv.THRESH_OTSU)\n",
    "\n",
    "se = cv.getStructuringElement(cv.MORPH_RECT, (10, 10), (-1, -1))\n",
    "binary = cv.morphologyEx(binary, cv.MORPH_CLOSE, se)\n",
    "cv.imshow(\"binary\", binary)\n",
    "\n",
    "contours,hierachy=cv.findContours(binary,cv.RETR_EXTERNAL,cv.CHAIN_APPROX_SIMPLE)\n",
    "height, width = src.shape[:2]\n",
    "for c in range(len(contours)):\n",
    "    x, y, w, h = cv.boundingRect(contours[c])\n",
    "    area = cv.contourArea(contours[c])\n",
    "    if h > (height//2):\n",
    "        continue\n",
    "    if area < 150:\n",
    "        continue\n",
    "    cv.rectangle(src, (x, y), (x+w, y+h), (0, 0, 255), 1, 8, 0)\n",
    "    cv.drawContours(src, contours, c, (0, 255, 0), 1, 8)\n",
    "\n",
    "cv.imshow(\"result\", src)\n",
    "cv.imwrite(\"result.jpg\", src)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "496862cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_23836/3467771777.py, line 190)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\shrey\\AppData\\Local\\Temp/ipykernel_23836/3467771777.py\"\u001b[1;36m, line \u001b[1;32m190\u001b[0m\n\u001b[1;33m    if cv2.waitKey(25) & 0xFF == ord('q'):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Prototype 5\n",
    "\n",
    "# importing the necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# defining the crack detector function\n",
    "   \n",
    "# here weak_th and strong_th are thresholds for\n",
    "# double thresholding step\n",
    "def PCD(img, weak_th = None, strong_th = None):\n",
    "    \n",
    "    # Bilateral Filter\n",
    "    img = cv2.bilateralFilter(img,18,80,80)\n",
    "    \n",
    "    # conversion of image to grayscale\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #Particle Denoising\n",
    "    img = cv2.fastNlMeansDenoising(img,10,10,7,21)\n",
    "\n",
    "    # Noise reduction step\n",
    "    #img = cv2.GaussianBlur(img, (5, 5), 1.6)\n",
    "       \n",
    "    # Calculating the gradients\n",
    "    gx = cv2.Sobel(np.float32(img), cv2.CV_64F, 1, 0, 3)\n",
    "    gy = cv2.Sobel(np.float32(img), cv2.CV_64F, 0, 1, 3)\n",
    "      \n",
    "    # Conversion of Cartesian coordinates to polar \n",
    "    mag, ang = cv2.cartToPolar(gx, gy, angleInDegrees = True)\n",
    "       \n",
    "    # setting the minimum and maximum thresholds \n",
    "    # for double thresholding\n",
    "    mag_max = np.max(mag)\n",
    "    if not weak_th:weak_th = mag_max * 0.1\n",
    "    if not strong_th:strong_th = mag_max * 0.5\n",
    "      \n",
    "    # getting the dimensions of the input image  \n",
    "    height, width = img.shape\n",
    "       \n",
    "    # Looping through every pixel of the grayscale \n",
    "    # image\n",
    "    for i_x in range(width):\n",
    "        for i_y in range(height):\n",
    "               \n",
    "            grad_ang = ang[i_y, i_x]\n",
    "            grad_ang = abs(grad_ang-180) if abs(grad_ang)>180 else abs(grad_ang)\n",
    "               \n",
    "            # selecting the neighbours of the target pixel\n",
    "            # according to the gradient direction\n",
    "            # In the x axis direction\n",
    "            if grad_ang<= 22.5:\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y\n",
    "              \n",
    "            # top right (diagonal-1) direction\n",
    "            elif grad_ang>22.5 and grad_ang<=(22.5 + 45):\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y-1\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y + 1\n",
    "              \n",
    "            # In y-axis direction\n",
    "            elif grad_ang>(22.5 + 45) and grad_ang<=(22.5 + 90):\n",
    "                neighb_1_x, neighb_1_y = i_x, i_y-1\n",
    "                neighb_2_x, neighb_2_y = i_x, i_y + 1\n",
    "              \n",
    "            # top left (diagonal-2) direction\n",
    "            elif grad_ang>(22.5 + 90) and grad_ang<=(22.5 + 135):\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y + 1\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y-1\n",
    "              \n",
    "            # Now it restarts the cycle\n",
    "            elif grad_ang>(22.5 + 135) and grad_ang<=(22.5 + 180):\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y\n",
    "               \n",
    "            # Non-maximum suppression step\n",
    "            if width>neighb_1_x>= 0 and height>neighb_1_y>= 0:\n",
    "                if mag[i_y, i_x]<mag[neighb_1_y, neighb_1_x]:\n",
    "                    mag[i_y, i_x]= 0\n",
    "                    continue\n",
    "   \n",
    "            if width>neighb_2_x>= 0 and height>neighb_2_y>= 0:\n",
    "                if mag[i_y, i_x]<mag[neighb_2_y, neighb_2_x]:\n",
    "                    mag[i_y, i_x]= 0\n",
    "   \n",
    "    weak_ids = np.zeros_like(img)\n",
    "    strong_ids = np.zeros_like(img)              \n",
    "    ids = np.zeros_like(img)\n",
    "       \n",
    "    # double thresholding step\n",
    "    for i_x in range(width):\n",
    "        for i_y in range(height):\n",
    "              \n",
    "            grad_mag = mag[i_y, i_x]\n",
    "              \n",
    "            if grad_mag<weak_th:\n",
    "                mag[i_y, i_x]= 0\n",
    "            elif strong_th>grad_mag>= weak_th:\n",
    "                ids[i_y, i_x]= 1\n",
    "            else:\n",
    "                ids[i_y, i_x]= 2\n",
    "       \n",
    "       \n",
    "    # finally returning the magnitude of\n",
    "    # gradients of edges\n",
    "    return mag\n",
    "\n",
    "#Shi tomasi\n",
    "\n",
    "def shi_tomasi(image):\n",
    "\n",
    "    #Converting to grayscale\n",
    "    gray_img = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #Specifying maximum number of corners as 1000\n",
    "    # 0.01 is the minimum quality level below which the corners are rejected\n",
    "    # 10 is the minimum euclidean distance between two corners\n",
    "    corners_img = cv2.goodFeaturesToTrack(gray_img,1000,0.01,10)\n",
    "    \n",
    "    corners_img = np.int0(corners_img)\n",
    "\n",
    "    for corners in corners_img:\n",
    "       \n",
    "        x,y = corners.ravel()\n",
    "        #Circling the corners in green0\n",
    "        cv2.circle(image,(x,y),3,[0,255,0],-1)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "# Creating a VideoCapture object to read the video\n",
    "cap = cv2.VideoCapture('Sam.mp4')\n",
    " \n",
    " \n",
    "# Loop until the end of the video\n",
    "while (cap.isOpened()):\n",
    " \n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, (540, 380), fx = 0, fy = 0,\n",
    "                         interpolation = cv2.INTER_CUBIC)\n",
    " \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame', frame)\n",
    " \n",
    "    # conversion of BGR to grayscale is necessary to apply this operation\n",
    "   \n",
    "    \n",
    "    crack_frame = PCD(frame)\n",
    "    \n",
    "    #blur = cv2.blur(crack_frame,(3,3))\n",
    "    cv2.imshow('C_frame', crack_frame)\n",
    "    #shi= shi_tomasi(frame)\n",
    "    #cv2.imshow('Shi',shi)\n",
    "    #img_log = np.array(blur,dtype=np.uint8)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = cv2.bilateralFilter(frame,18,80,80)\n",
    "    frame = cv2.fastNlMeansDenoising(frame,10,10,7,21)\n",
    "    Canny= cv2.Canny(frame,100,200)\n",
    "    cv2.imshow('P6',Canny)\n",
    "   \n",
    "    # Morphological Closing Operator\n",
    "    #kernel = np.ones((5,5),np.uint8)\n",
    "    #closing = cv2.morphologyEx(blur, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Create feature detecting method\n",
    "    # sift = cv2.xfeatures2d.SIFT_create()\n",
    "    # surf = cv2.xfeatures2d.SURF_create()\n",
    "    # orb = cv2.ORB_create(nfeatures=150)\n",
    "    \n",
    "    # Make featured Image\n",
    "    # keypoints, descriptors = orb.detectAndCompute(closing, None)\n",
    "    # featuredImg = cv2.drawKeypoints(closing, keypoints, None)\n",
    "    \n",
    "\n",
    "    # adaptive thresholding to use different threshold\n",
    "    # values on different regions of the frame.\n",
    "    Thresh = cv2.adaptiveThreshold(crack_frame, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                           #cv2.THRESH_BINARY_INV, 11, 2)\n",
    " \n",
    "    \n",
    "    \n",
    "    # define q as the exit button\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "# release the video capture object\n",
    "cap.release()\n",
    "# Closes all the windows currently opened.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64381bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
